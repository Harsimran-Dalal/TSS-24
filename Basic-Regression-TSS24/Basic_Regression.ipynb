{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":82149,"databundleVersionId":8952049,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import mean_squared_log_error\nfrom xgboost import XGBRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-27T20:12:30.882256Z","iopub.execute_input":"2024-06-27T20:12:30.883289Z","iopub.status.idle":"2024-06-27T20:12:30.908893Z","shell.execute_reply.started":"2024-06-27T20:12:30.883247Z","shell.execute_reply":"2024-06-27T20:12:30.907494Z"},"trusted":true},"execution_count":198,"outputs":[{"name":"stdout","text":"/kaggle/input/tss24-competition-4/sample_submission.csv\n/kaggle/input/tss24-competition-4/train.csv\n/kaggle/input/tss24-competition-4/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"#Load the data\ntrain = pd.read_csv('/kaggle/input/tss24-competition-4/train.csv')\ntest = pd.read_csv('/kaggle/input/tss24-competition-4/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/tss24-competition-4/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-27T20:12:32.423859Z","iopub.execute_input":"2024-06-27T20:12:32.424278Z","iopub.status.idle":"2024-06-27T20:12:32.620002Z","shell.execute_reply.started":"2024-06-27T20:12:32.424244Z","shell.execute_reply":"2024-06-27T20:12:32.618642Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"# Assuming 'Rings' is the target variable and 'id' is the identifier\nX = train.drop(columns=['Rings', 'id'])\ny = train['Rings']\nX_test = test.drop(columns=['id'])\n\n# Encode categorical features using Label Encoding\nlabel_encoders = {}\nfor column in X.select_dtypes(include=['object']).columns:\n    label_encoders[column] = LabelEncoder()\n    X[column] = label_encoders[column].fit_transform(X[column])\n    X_test[column] = label_encoders[column].transform(X_test[column])\n\n# Feature scaling\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nX_test_scaled = scaler.transform(X_test)\n\n# Split the training data into train and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Train models\nmodel_xgb = XGBRegressor(n_estimators=50, learning_rate=0.1, random_state=42)\nmodel_xgb.fit(X_train, y_train)\n\nmodel_rf = RandomForestRegressor(n_estimators=50, random_state=42)\nmodel_rf.fit(X_train, y_train)\n\n# Make predictions\ny_pred_xgb = model_xgb.predict(X_val)\ny_pred_rf = model_rf.predict(X_val)\ny_test_pred_xgb = model_xgb.predict(X_test_scaled)\ny_test_pred_rf = model_rf.predict(X_test_scaled)\n\n# Calculate RMSLE for each model\nrmsle_xgb = np.sqrt(mean_squared_log_error(y_val, y_pred_xgb))\nrmsle_rf = np.sqrt(mean_squared_log_error(y_val, y_pred_rf))\nprint(f'Validation RMSLE - XGBoost: {rmsle_xgb}')\nprint(f'Validation RMSLE - RandomForest: {rmsle_rf}')\n\n# Blended predictions (equal weights for simplicity)\nblended_predictions = (y_test_pred_xgb + y_test_pred_rf) / 2\n\n# Prepare the submission file\nsubmission = sample_submission.copy()\nsubmission['Rings'] = blended_predictions\n\n# Save the submission file\nsubmission.to_csv('blended_submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T20:25:11.396861Z","iopub.execute_input":"2024-06-27T20:25:11.397282Z","iopub.status.idle":"2024-06-27T20:25:33.504805Z","shell.execute_reply.started":"2024-06-27T20:25:11.397250Z","shell.execute_reply":"2024-06-27T20:25:33.503246Z"},"trusted":true},"execution_count":202,"outputs":[{"name":"stdout","text":"Validation RMSLE - XGBoost: 0.15347137131407518\nValidation RMSLE - RandomForest: 0.15696626617397205\n","output_type":"stream"}]}]}